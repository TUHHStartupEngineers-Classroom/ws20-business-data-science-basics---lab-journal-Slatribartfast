---
title: "Journal (reproducible report)"
author: "Alexander Brosig"
date: "2020-11-05"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE,cache.lazy = FALSE)
```

# Intro to the tidyverse
## Challange I
```{r c1challenge_1, fig.width=14, fig.height=7}
# 1.0 Load libraries ----
library(tidyverse)
library(readxl)
library(lubridate)
library("writexl")
library(stringr)
library(dplyr)
library(tidyr)

# 2.0 Importing Files ----
bikes_tbl      <- read_excel(path = "00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
bikeshops_tbl  <- read_excel("00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")

# 3.0 Examining Data ----
#glimpse(bikes_tbl)
#glimpse(orderlines_tbl)
#glimpse(bikeshops_tbl)
# 4.0 Joining Data ----
bikeSaleLocation_tbl <- orderlines_tbl %>%
  left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
  left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))
#bikeSaleLocation_tbl %>% glimpse()

# 5.0 Wrangling Data ----
bikeSaleLocation_tbl_wrangeled <- bikeSaleLocation_tbl %>%
  separate("location",c("city","state"),", ")  %>%
  mutate(total.price = price * quantity) %>%
  select(-order.line, -gender,-model.year,-frame.material,-weight,-category,-url,-lat,-lng)   

#glimpse(bikeSaleLocation_tbl_wrangeled)

###########
###TASK1###
###########

# 6.0 Business Insights ----
# 6.1 Sales by State ---
salesPerState_tbl <- bikeSaleLocation_tbl_wrangeled %>%
  select(total.price,state) %>%
  group_by(state) %>%
  summarize(sales = sum(total.price)) %>%
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))
#glimpse(salesPerState_tbl)

# Step 2 - Visualize
salesPerState_tbl %>%
  
  # Setup canvas with the columns year (x-axis) and sales (y-axis)
  ggplot(aes(x = state, y = sales)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = sales_text)) + # Adding labels to the bars
  
  
  # Formatting
  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. 
  # Again, we have to adjust it for euro values
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by state",
    subtitle = "A nice to have information",
    x = "", # Override defaults for x and y
    y = "Revenue"
  ) + theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

## Challange II
```{r c1challenge_2, fig.width=14, fig.height=7}

# Data Science at TUHH ------------------------------------------------------
# SALES ANALYSIS ----

# 1.0 Load libraries ----
library(tidyverse)
library(readxl)
library(lubridate)
library("writexl")
library(stringr)
library(dplyr)
library(tidyr)

# 2.0 Importing Files ----
bikes_tbl      <- read_excel(path = "00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
bikeshops_tbl  <- read_excel("00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")

# 3.0 Examining Data ----
#glimpse(bikes_tbl)
#glimpse(orderlines_tbl)
#glimpse(bikeshops_tbl)
# 4.0 Joining Data ----
bikeSaleLocation_tbl <- orderlines_tbl %>%
  left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
  left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))
#bikeSaleLocation_tbl %>% glimpse()

# 5.0 Wrangling Data ----
bikeSaleLocation_tbl_wrangeled <- bikeSaleLocation_tbl %>%
  separate("location",c("city","state"),", ")  %>%
  mutate(total.price = price * quantity) %>%
  select(-order.line, -gender,-model.year,-frame.material,-weight,-category,-url,-lat,-lng)   

#glimpse(bikeSaleLocation_tbl_wrangeled)


# 6.2 Sales by State and Year

# Step 1 - Manipulate
salesPerStateAndYear_tbl <- bikeSaleLocation_tbl_wrangeled %>%
  select(total.price,state,order.date) %>%
  mutate(year = year(order.date)) %>%
  group_by(year, state) %>%
  summarize(sales = sum(total.price))%>%
  ungroup() %>%
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))
#glimpse(salesPerStateAndYear_tbl)

# Step 2 - Visualize
salesPerStateAndYear_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = sales, fill = state)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  
  # Facet
  facet_wrap(~ state) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and state",
    subtitle = "nice to see statewise",
    fill = "Main category" # Changes the legend name
  )

```


# Data Acquisition
## Challange I
```{r c2challenge_1, fig.width=14, fig.height=7}
library("httr")
library("jsonlite")

res = GET("http://api.open-notify.org/astros.json")
data = fromJSON(rawToChar(res$content))
data
```

## Challange II
```{r c2challenge_2, fig.width=14, fig.height=7}
# WEBSCRAPING ----

# 1.0 LIBRARIES ----

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(furrr)     # Parallel Processing using purrr (iteration)
library(htm2txt)

#1.1 COLLECT PRODUCT FAMILIES ----
#the bike website category to use
url_mtb_enduro       <- "https://www.rosebikes.de/fahrr%C3%A4der/mtb/trail-/-enduro"
xopen(url_mtb_enduro) # Open links directly from RStudio to inspect them

# Read in the HTML for the entire webpage
url_mtb_enduro         <- read_html(url_mtb_enduro)
bike_names <- url_mtb_enduro %>%
  html_nodes(".catalog-category-bikes__title")%>%
  str_remove_all(".*>")%>%
  str_remove_all("\n")
bike_prices <- url_mtb_enduro %>%
  html_nodes(".catalog-category-bikes__price-title")%>%
  str_remove_all(".*>")%>%
  str_remove_all("\n")
  
#the phrases found in the tags are used to filter four bikes and prices 

#bike_names
#bike_prices


bike_data_tbl <- tibble()
bike_data_tbl_names <- as_tibble(bike_names)
bike_data_tbl_names <- tibble::rowid_to_column(bike_data_tbl_names, "ID")
bike_data_tbl_names


bike_data_tbl_prices <- as_tibble(bike_prices)
bike_data_tbl_prices <- tibble::rowid_to_column(bike_data_tbl_prices, "ID")
bike_data_tbl_prices



bike_data_tbl <- bike_data_tbl_names %>%
  left_join(bike_data_tbl_prices, by = c("ID" = "ID"))%>%
  rename("bike_name" = "value.x") %>%
  rename("bike_price" = "value.y")


bike_data_tbl
# saving is not so usefull for the compilation on the website, so i leave it out here
#saveRDS(bike_data_tbl, "bike_data_tbl.rds")

```


# Data Wrangling
## Challange I
```{r c3challenge_1, fig.width=14, fig.height=7}
library(vroom)
library(tidyverse)
library(readxl)
library(lubridate)
library("writexl")
library(stringr)
library(dplyr)
library(tidyr)

col_types <- list(
  id = col_character(),
  type = col_character(),
  number = col_character(),
  country = col_character(),
  date = col_date("%Y-%m-%d"),
  abstract = col_character(),
  title = col_character(),
  kind = col_character(),
  num_claims = col_double(),
  filename = col_character(),
  withdrawn = col_double()
)

#load stuff
assignee_tbl <- vroom(
  file       = "./00_data/assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
patent_assignee_tbl <- vroom(
  file       = "./00_data/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)

#gen table
Patent_Dominance_tbl <- tibble()

#filter us companys
assignee_tbl <- assignee_tbl %>%
  filter(type == 2)

#assamble
Patent_Dominance_tbl <- assignee_tbl %>%
  left_join(patent_assignee_tbl, by = c("id" = "assignee_id")) %>%
  group_by(organization) %>%
  summarise(count = n())%>%
  arrange(desc(count))%>%
  slice(1:10)

#show
glimpse(Patent_Dominance_tbl)
```
## Challange II
```{r c3challenge_2, fig.width=14, fig.height=7}
library(vroom)
library(tidyverse)
library(readxl)
library(lubridate)
library("writexl")
library(stringr)
library(dplyr)
library(tidyr)

col_types <- list(
  id = col_character(),
  type = col_character(),
  number = col_character(),
  country = col_character(),
  date = col_date("%Y-%m-%d"),
  abstract = col_character(),
  title = col_character(),
  kind = col_character(),
  num_claims = col_double(),
  filename = col_character(),
  withdrawn = col_double()
)


#load stuff
assignee_tbl <- vroom(
  file       = "./00_data/assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
patent_assignee_tbl <- vroom(
  file       = "./00_data/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
patent_tbl <- vroom(
  file       = "./00_data/patent.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)

#genearte stuff
Recent_patent_acitivity_tbl <- tibble()

#filter us companys
assignee_tbl <- assignee_tbl %>%
  filter(type == 2)

#assamble it
Recent_patent_acitivity_tbl <- assignee_tbl %>%
  left_join(patent_assignee_tbl, by = c("id" = "assignee_id")) %>%
  left_join(patent_tbl, by = c("patent_id" = "id")) %>%
  mutate(year = year(date)) %>%
  filter(year == 2019)%>%
  group_by(organization) %>%
  summarise(count = n())%>%
  arrange(desc(count))%>%
  slice(1:10)

#show it
glimpse(Recent_patent_acitivity_tbl)
```
## Challange III
```{r c3challenge_3, fig.width=14, fig.height=7}
library(vroom)
library(tidyverse)
library(stringr)
library(dplyr)

col_types <- list(
  id = col_character(),
  type = col_character(),
  number = col_character(),
  country = col_character(),
  date = col_date("%Y-%m-%d"),
  abstract = col_character(),
  title = col_character(),
  kind = col_character(),
  num_claims = col_double(),
  filename = col_character(),
  withdrawn = col_double()
)

#load stuff
assignee_tbl <- vroom(
  file       = "./00_data/assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
patent_assignee_tbl <- vroom(
  file       = "./00_data/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
uspc_tbl <- vroom(
  file       = "./00_data/uspc.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)
mainclass_current_tbl <- vroom(
  file       = "./00_data/mainclass_current.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")
)



#generate tibbles
getTenTable <- tibble()
wholeTable <- tibble()
filterdTable<- tibble()
filterdTable_summeried<- tibble()

#filter companys
assignee_tbl <- assignee_tbl %>%
  filter(type == 2 | type == 3)


#get the 10 biggest companys
getTenTable <- assignee_tbl %>%
  left_join(patent_assignee_tbl, by = c("id" = "assignee_id")) %>%
  left_join(uspc_tbl, by = c("patent_id" = "patent_id")) %>%
  #filter(!is.na(mainclass_id))%>%
  group_by(organization) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  ungroup() %>%
  slice(1:10)

topTen <- getTenTable[,c("organization")]

#put together everything
wholeTable <- assignee_tbl %>%
  left_join(patent_assignee_tbl, by = c("id" = "assignee_id")) %>%
  left_join(uspc_tbl, by = c("patent_id" = "patent_id"))

#filter the big 10 
filterdTable <- subset(wholeTable, wholeTable$organization %in% c(topTen[1,1],topTen[2,1],topTen[3,1],topTen[4,1],topTen[5,1],topTen[6,1],topTen[7,1],topTen[8,1],topTen[9,1],topTen[10,1]))

#assable the summary
filterdTable_summeried <- filterdTable %>%
  filter(!is.na(mainclass_id))%>%
  group_by(mainclass_id) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  ungroup() %>%
  left_join(mainclass_current_tbl, by = c("mainclass_id" = "id")) %>%
  slice(1:10)


#show 
glimpse(filterdTable_summeried)
  
```

# Data Visualization
## Challange I
```{r c4challenge_1, fig.width=14, fig.height=7}

# Chapter 05 - Challenge 1 ----

# import libraries ----

library(tidyverse)
library(lubridate)

# import data ----

covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")
#make it more nice
covid_data_tbl <- covid_data_tbl%>% 
  mutate(across(countriesAndTerritories, str_replace_all, "_", " "))


# assamble stuff
assambled_tbl <- covid_data_tbl %>%
  mutate(date = dmy(dateRep)) %>%
  arrange(date) %>%
  filter(countriesAndTerritories %in% c("Germany","Spain", "France", "United Kingdom", "United States of America")) %>%
  filter(year == "2020") %>%
  group_by(countriesAndTerritories) %>%
  mutate(cumulative_cases = cumsum(cases)) %>%
  ungroup()

#plot stuff
assambled_tbl %>%
  ggplot(aes(date, cumulative_cases), color = countriesAndTerritories) +
  geom_line(aes(x     = date,
                y     = cumulative_cases,
                color = countriesAndTerritories)) + 
  
  scale_x_date(breaks = "1 month", minor_breaks = "1 month", date_labels = "%B") +
  scale_y_continuous(labels = scales::dollar_format(prefix = "", suffix = "")) +
  geom_label(aes(label = cumulative_cases),
             size  = 5,
             nudge_x  = -40,
             nudge_y  = 5,
             fill  = "#981fc4",
             color = "white",
             fontface = "italic",
             data = filter(assambled_tbl,date == max(date) & cumulative_cases == max(cumulative_cases)))+
  theme_light() +
  
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
    plot.title = element_text(face = "bold"),
    plot.caption = element_text(face = "bold.italic"),
    plot.background = element_blank(),
    axis.title = element_text(face = "bold")
  ) +
  
  labs(
    title = "COVID-19 confirmed cases worldwide",
    subtitle = "The united States leads the battle nobody wants to win",
    x = "Year 2020",
    y = "Cumulative Cases",
    color = "Continent / Country" # Legend text
  )

```

## Challange II
```{r c4challenge_2, fig.width=14, fig.height=7}

# import libraries ----

library(tidyverse)
library(ggplot2)
library(maps)


covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")


#assamble it
covid_data_tbl <- covid_data_tbl %>% 
  mutate(across(countriesAndTerritories, str_replace_all, "_", " ")) %>%
  mutate(countriesAndTerritories = case_when(
    countriesAndTerritories == "United Kingdom" ~ "UK",
    countriesAndTerritories == "United States of America" ~ "USA",
    countriesAndTerritories == "Czechia" ~ "Czech Republic",
    TRUE ~ countriesAndTerritories
    
  ))


covid_mortality_tbl <- covid_data_tbl %>%
  select(countriesAndTerritories, deaths, popData2019, cases) %>%
  group_by(countriesAndTerritories) %>%
  summarize(population_2019 = mean(popData2019), deaths_sum = sum(deaths)) %>%
  mutate(`Mortality Rate / %`   = 100 * deaths_sum / population_2019)%>%
  ungroup()


  
# show it
world <- map_data("world")
world <- left_join(world, covid_mortality_tbl, by = c("region" = "countriesAndTerritories"))
world <- select(world,-"order")



ggplot() +
geom_polygon(data = world, aes(x=long, y = lat,fill = `Mortality Rate / %`, group = group))+ 
  
coord_fixed(1.3) +
  
scale_fill_gradient(low='#EC4440', high='#2F142C') +
theme(axis.title.x=element_blank(), axis.text.x=element_blank(),axis.ticks.x=element_blank())+
  theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
  labs(title = "Confirmed COVIS-19 deaths relativ to the size of the population",
       subtitle = "More then 1.2 Million confirmed COVID-19 deaths worldwide")


```


